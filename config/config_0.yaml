# recurrent architecture
arch: gru
# batch size
bs: 512
# dropout
do: 0.25
# learning rate
lr: 0.0005
# recurrent network size
nh: 96
# latent space size
nl: 64
# number of recurrent layers
nlayers: 2
# output size
nout: 1
# weight decay weight
wd: 0.0