# recurrent architecture
arch: gru
# batch size
bs: 1024
# training device
d: cuda:1
# dropout
do: 0.5
# learning rate
lr: 0.0001
# recurrent network size
nh: 96
# latent space size
nl: 8
# number of recurrent layers
nlayers: 2
# output size
nout: 1
# early stopping patience
patience: 1000
# number of repetitions
rep: 5
# weight decay weight
wd: 0.0
# folded light curves
fold: false
# max lr
max_lr: 0.02
# beta_r
beta_r: 0.98
# beta_e
beta_e: 1.005